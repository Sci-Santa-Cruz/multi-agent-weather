{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17402b00-1bac-44eb-a33b-89259331b6e2",
   "metadata": {},
   "source": [
    "# Estrategia de Despliegue\n",
    "\n",
    "## Objetivo\n",
    "Este notebook desarrolla una estrategia para desplegar nuestro sistema multiagente en un entorno de producciÃ³n. Abordaremos requisitos de infraestructura, escalabilidad, seguridad y otras consideraciones operativas esenciales.\n",
    "\n",
    "En este notebook:\n",
    "- Checklist de pruebas de paso a producciÃ³n\n",
    "- Definiremos la arquitectura de infraestructura necesaria ()\n",
    "- Planificaremos estrategias de escalado y rendimiento\n",
    "- Abordaremos consideraciones de seguridad y privacidad\n",
    "- DiseÃ±aremos procesos de despliegue y actualizaciÃ³n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb7e940-8982-4695-a02f-89381f164eb3",
   "metadata": {},
   "source": [
    "## Propuesta de Arquitectura de Infraestructura\n",
    "\n",
    "Para el despliegue en producciÃ³n, considero que las dos opciones mÃ¡s fuertes son **AWS Bedrock** y **LangGraph**. Dependiendo del enfoque y las necesidades especÃ­ficas de cada etapa del proyecto, elegirÃ­a entre una y otra.\n",
    "\n",
    "**AWS Bedrock**: Si buscamos algo rÃ¡pido para las primeras iteraciones del MVP o un producto inicial, esta es una excelente opciÃ³n. Es un servicio completamente gestionado, sin necesidad de infraestructura, y con facturaciÃ³n flexible basada en uso. Bedrock permite que nos enfoquemos en el desarrollo sin preocuparnos por la gestiÃ³n de servidores. AdemÃ¡s, soporta la colaboraciÃ³n de mÃºltiples agentes, lo cual es Ãºtil para comenzar de manera Ã¡gil y rÃ¡pida.\n",
    "\n",
    "**LangGraph**: Si nuestra prioridad en la siguiente fase es una trazabilidad detallada, depuraciÃ³n avanzada de workflows y control total de la infraestructura, **LangGraph** (junto con **LangSmith**) es una opciÃ³n mÃ¡s adecuada. Esto es ideal cuando ya hemos alcanzado un punto donde necesitamos afinar procesos, manejar flujos de trabajo mÃ¡s complejos y tener mÃ©tricas e informaciÃ³n en tiempo real, todo sin perder flexibilidad en el desarrollo.\n",
    "\n",
    "## Proceso sugerido:\n",
    "\n",
    "**Para un Proof-of-Concept rÃ¡pido**: ComenzarÃ­a con **AWS Bedrock**. Nos permitirÃ¡ poner algo en producciÃ³n rÃ¡pidamente, con una infraestructura serverless que facilita la implementaciÃ³n sin complicaciones. Esto es perfecto para las primeras iteraciones del MVP, donde la velocidad y la flexibilidad son esenciales.\n",
    "\n",
    "**Si surge la necesidad de mÃ¡s control sobre la infraestructura y trazabilidad**: Dado que **LangGraph** es una biblioteca agnÃ³stica que se puede utilizar tanto en **AWS Bedrock** como en **LangGraph Platform**, si en algÃºn momento se requiere mÃ¡s control sobre los flujos, mÃ©tricas o trazabilidad, podemos considerar migrarnos a **LangGraph Platform**. Esto nos permitirÃ¡ tener un control mÃ¡s detallado sobre los procesos y la infraestructura sin perder la flexibilidad que ya tenemos.\n",
    "\n",
    "---\n",
    "\n",
    "## Opciones de Plataforma para ProducciÃ³n\n",
    "\n",
    "| CaracterÃ­stica                  | **AWS Bedrock**                                                                                                    | **LangGraph (LangChain)**                                                                                             |\n",
    "|----------------------------------|---------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------|\n",
    "| **Modelo de servicio**          | Fully managed â€œpay-as-you-goâ€ LLM service en AWS.                                                                  | Infraestructura componible â€œinfrastructure-as-codeâ€ para orquestar agentes, tightly integrated con LangSmith.         |\n",
    "| **Multi-agent support**         | Multi-agent collaboration capability (preview) nativo.                                                              | DiseÃ±ado para flujos de trabajo agent-centric y grÃ¡ficos cÃ­clicos de agentes; orquesta agentes especializados.         |\n",
    "| **Trazabilidad & Debugging**    | Se integra con CloudWatch; no ofrece UI especÃ­fica para agentes LLM.                                                | LangSmith + LangGraph Studio: trazabilidad de eventos, streaming de estado y debugging visual.                       |\n",
    "| **Despliegue & Escalado**       | Escalado automÃ¡tico vÃ­a AWS Serverless (Fargate, Lambda) y Bedrock Flows.                                           | Despliegue en Kubernetes o serverless; LangGraph maneja la orquestaciÃ³n sin infraestructura adicional.               |\n",
    "| **Costos**                      | Pago por token y uso de servicio; se pueden optimizar con autoscaling y lÃ­mites de presupuesto.                     | MÃ¡s control de costos si se autohospeda; se paga por infraestructura subyacente.                                      |\n",
    "| **Interfaz de developer UX**    | Consola AWS estÃ¡ndar; Bedrock Flows ofrece UI drag-and-drop para pipelines.                                         | SDKs en Python/JS, CLI y UI de LangSmith; enfoque en iteraciÃ³n rÃ¡pida y observabilidad.                               |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17762bd5-3586-4f8a-8f32-9f35188a5dd1",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Paso a ProducciÃ³n\n",
    "\n",
    "\n",
    "Una vez priorizados y revisados los puntos clave descritos en las tareas futuras del Notebook NÂ° 10 y las consideraciones del Notebook NÂ° 6, estos representan los Ãºltimos pasos antes de proceder a producciÃ³n. Es esencial afinar y validar estos detalles finales para asegurar que todo estÃ© listo.\n",
    "\n",
    "Antes de dar el paso definitivo a producciÃ³n, debemos revisar y confirmar que nuestro Checklist estÃ© completamente validado, con la flexibilidad de poder agregar o modificar puntos segÃºn sea necesario. Esto garantizarÃ¡ que todos los aspectos crÃ­ticos estÃ©n cubiertos y que el sistema estÃ© preparado para su implementaciÃ³n final.\n",
    "\n",
    "\n",
    "### 1. Observabilidad\n",
    "\n",
    "- Backen Robustos y con estrategia de feedback\n",
    "\n",
    "_herramientas_ : LangGraph Platform\n",
    "\n",
    "- Logs estructurados para depuraciÃ³n.\n",
    "  - _Herramientas_: `structlog`, `loguru`.\n",
    "- MÃ©tricas expuestas para monitoreo.\n",
    "  - _Herramientas_: `Prometheus + Grafana`, `Elastic + Kibana`, `LangSmith`.\n",
    "\n",
    "### 2. Feature Toggles\n",
    "\n",
    "- Variables de entorno para activar o desactivar funcionalidades.\n",
    "  - _Ejemplo_: `DISABLE_LLM=True`.\n",
    "\n",
    "### 3. Failover\n",
    "\n",
    "- Uso de respuestas por defecto si el LLM falla.\n",
    "  - _Ejemplo_: Mensajes genÃ©ricos o cache local.\n",
    "\n",
    "### 4. Rollback\n",
    "\n",
    "- Versionado del cÃ³digo para revertir cambios fÃ¡cilmente.\n",
    "  - _Herramientas_: `git tags`, CI/CD pipelines.\n",
    "\n",
    "### 5. Pruebas End-to-End\n",
    "\n",
    "- Validar toda la cadena: entrada â†’ procesamiento â†’ salida.\n",
    "  - _Herramientas_: Tests de integraciÃ³n con fixtures y mocks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f2cfc9-4834-4c71-a069-4f726d00165a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# âœ… **Checklist de Paso a ProducciÃ³n para Agente Multi-Funcional** (ver0.0.1)\n",
    "\n",
    "> Basado en [ML Test Score](https://testing.googleblog.com/2016/06/testing-and-validation-of-machine.html), 12-Factor App, MLOps maturity, y prÃ¡cticas de desarrollo y despliegue de agentes con LLMs.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”§ CÃ³digo y MÃ³dulos\n",
    "\n",
    "- [ ] Todos los mÃ³dulos estÃ¡n encapsulados como clases (no funciones sueltas).\n",
    "- [ ] No hay valores hardcodeados: todos los valores sensibles o variables estÃ¡n en archivos de configuraciÃ³n.\n",
    "- [ ] Existe un archivo de configuraciÃ³n centralizado (`config.yaml`, `.env`, `settings.py`, etc.) documentado y usado en todo el sistema.\n",
    "- [ ] Todo el cÃ³digo sigue el estÃ¡ndar PEP 8, con herramientas como `black`, `ruff`, `isort`.\n",
    "- [ ] Prompts separados en mÃ³dulos reutilizables.\n",
    "- [ ] LLMs instanciados a travÃ©s de un Ãºnico mÃ³dulo de fÃ¡brica, adaptado al tipo de agente.\n",
    "\n",
    "---\n",
    "\n",
    "## âš™ï¸ ConfiguraciÃ³n y Flags\n",
    "\n",
    "- [ ] Variables sensibles se cargan desde el entorno (`.env`) o sistema de configuraciÃ³n.\n",
    "- [ ] Feature toggles: puedes desactivar/activar mÃ³dulos como `DISABLE_LLM`, `USE_FAKE_DATA`, `ENABLE_VERBOSE_LOGGING`, etc.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§ª Pruebas\n",
    "\n",
    "### TÃ©cnicas\n",
    "- [ ] Pruebas unitarias para cada componente (incluyendo nodos y respuestas esperadas).\n",
    "- [ ] Pruebas de covertura con un porcetaje superior al 95%\n",
    "- [ ] ValidaciÃ³n de comportamiento ante:\n",
    "  - [ ] Timeouts\n",
    "  - [ ] Errores HTTP 5xx\n",
    "  - [ ] Datos incompletos o malformados\n",
    "- [ ] ValidaciÃ³n de formato de respuesta con `pydantic` o `cerberus`.\n",
    "- [ ] Pruebas de carga (`locust`, `artillery`, `asyncio`) para medir degradaciÃ³n a alto trÃ¡fico.\n",
    "- [ ] Mocks o fixtures con `pytest-httpx`, `responses`, etc.\n",
    "\n",
    "### Seguridad\n",
    "- [ ] `pip-audit`, `safety`, `bandit` aplicados para revisar dependencias y buenas prÃ¡cticas de seguridad.\n",
    "- [ ] No hay secretos o credenciales en el cÃ³digo fuente ni en logs.\n",
    "\n",
    "---\n",
    "\n",
    "## âš–ï¸ Ã‰ticas y Sesgos\n",
    "\n",
    "- [ ] EvaluaciÃ³n de sesgo en las respuestas del LLM, especialmente en temas sensibles (noticias, divisas).\n",
    "- [ ] Fuentes mÃºltiples para mitigar sesgo en noticias (o aclarar si hay una fuente dominante).\n",
    "- [ ] El agente tiene un mecanismo contra alucinar respuestas.\n",
    "Frameworks sugeridos: CheckList, Fairlearn.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§  EvaluaciÃ³n Cognitiva\n",
    "\n",
    "- [ ] Soporte para tareas mÃºltiples o ambiguas (ej. clima + noticias).\n",
    "- [ ] Respuestas consistentes ante reformulaciÃ³n.\n",
    "- [ ] Mantenimiento de idioma y tono uniforme.\n",
    "- [ ] EvaluaciÃ³n automÃ¡tica con:\n",
    "  - [ ] `LangSmith`\n",
    "  - [ ] `TruLens`\n",
    "  - [ ] `Ragas`\n",
    "\n",
    "[HumanEval](https://openai.com/research/gpt-4#methods\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“Š Observabilidad y Mantenimiento\n",
    "\n",
    "- [ ] Logs estructurados (`loguru`, `structlog`) con niveles configurables.\n",
    "- [ ] MÃ©tricas clave: tiempo de respuesta, fallos por mÃ³dulo, estado del LLM.\n",
    "- [ ] Dashboards activos (Prometheus + Grafana, o Elastic + Kibana).\n",
    "- [ ] Failover: si falla el LLM, el sistema sigue funcionando con respuestas bÃ¡sicas o estÃ¡ticas.\n",
    "- [ ] Healthchecks (`/healthz`, `/readyz`) implementados y monitoreados.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸš€ Despliegue\n",
    "\n",
    "- [ ] Dockerfile reproducible + CI/CD automatizado.\n",
    "- [ ] Sistema versionado con `git tags` o semver.\n",
    "- [ ] Rollback simple a versiÃ³n anterior.\n",
    "- [ ] Pruebas end-to-end desde entrada hasta respuesta, pasando por APIs y LLMs.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ Arquitectura\n",
    "\n",
    "- [ ] Diagrama C4 (nivel contenedor y componentes) actualizado.\n",
    "- [ ] DocumentaciÃ³n de mÃ³dulos y flujo de datos disponible (`docs/`, `README`, etc.).\n",
    "- [ ] Script de arranque/desarrollo (`make dev`, `start.sh`, `dev.env`, etc.).\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“¡ Interoperabilidad y Protocolos\n",
    "\n",
    "- [ ] IntegraciÃ³n lista para interacciÃ³n con servicios externos vÃ­a:\n",
    "  - [ ] **MCP: Protocolo de Contexto de Modelo**\n",
    "  - [ ] **A2A: ComunicaciÃ³n entre agentes**\n",
    "- [ ] DefiniciÃ³n clara de contexto y estado compartido si el agente opera en ecosistemas multiagente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b4f7ad-bc56-4078-a1e6-ef7bb19aaa22",
   "metadata": {},
   "source": [
    "\n",
    "#### ğŸ” **Permisos y Accesos**\n",
    "- [ ] Â¿El agente tiene permisos **mÃ­nimos y necesarios** para operar?\n",
    "- [ ] Â¿Se estÃ¡n utilizando **credenciales de solo lectura** cuando es posible?\n",
    "- [ ] Â¿Se restringiÃ³ el acceso solo a **recursos especÃ­ficos** (APIs, archivos, tablas)?\n",
    "- [ ] Â¿Se implementÃ³ **sandboxing** (contenedor, entorno restringido)?\n",
    "\n",
    "#### âš ï¸ **PrevenciÃ³n de uso indebido**\n",
    "- [ ] Â¿Se anticiparon formas maliciosas de uso del agente (borrado, modificaciÃ³n de datos)?\n",
    "- [ ] Â¿Se simularon escenarios de abuso para validar los lÃ­mites del sistema?\n",
    "\n",
    "#### ğŸ›¡ï¸ **Defensa en profundidad**\n",
    "- [ ] Â¿Se estÃ¡n combinando medidas (por ejemplo: permisos + sandbox)?\n",
    "- [ ] Â¿Se definieron reglas claras de acceso a recursos por tipo de tarea?\n",
    "\n",
    "#### ğŸ“‚ **Escenarios especÃ­ficos**\n",
    "- [ ] **Archivos**: Â¿El agente estÃ¡ limitado a un directorio especÃ­fico y solo accede a archivos seguros?\n",
    "- [ ] **APIs**: Â¿El agente usa claves de solo lectura o endpoints controlados?\n",
    "- [ ] **Bases de datos**: Â¿Las credenciales estÃ¡n restringidas a tablas puntuales y en modo solo lectura?\n",
    "\n",
    "#### ğŸ“‰ **MitigaciÃ³n de abuso y costos**\n",
    "- [ ] Â¿Hay verificaciÃ³n de cuentas (correo, telÃ©fono) para acceso a la app?\n",
    "- [ ] Â¿Existe un sistema de **rate limiting** por IP o usuario?\n",
    "- [ ] Â¿Se implementaron lÃ­mites de uso por sesiÃ³n, dÃ­a o usuario?\n",
    "\n",
    "#### ğŸ§  **ProtecciÃ³n contra inyecciÃ³n de prompts**\n",
    "- [ ] Â¿Se validan los prompts antes de enviarse al LLM?\n",
    "- [ ] Â¿Los prompts del sistema son **especÃ­ficos y cerrados** al dominio esperado?\n",
    "- [ ] Â¿Se auditan las respuestas para detectar comportamientos no deseados?\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
